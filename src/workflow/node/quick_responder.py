from typing import cast
from datetime import datetime, timezone

from langchain_core.messages import AIMessage
from pydantic import BaseModel, Field
from langchain_aws import ChatBedrockConverse
from langchain.prompts import ChatPromptTemplate
from langchain_core.prompt_values import PromptValue

from ..state import ResearchState
from ...logger import get_logger

logger = get_logger("quick_responder")


class ChatResponse(BaseModel):
    """ChatResponse represents the conversational response generated by the AI Chatbot."""

    content: str = Field(
        description="The content of the response, plain text or markdown.")


SYSTEM_PROMPT = """
You are Open Perplexity's ethical AI assistant.
Your goal is engaging in a conversation with the user and providing helpful responses.

## Ethics and Compliance
Your responses must align with our values:
<values>
- Integrity: Never deceive or aid in deception.
- Compliance: Refuse any request that violates laws or our policies.
- Privacy: Protect all personal and corporate data.
</values>
If a request conflicts with these values, respond: “I cannot perform that action as it goes against Open Perplexity's values.”

## Response format instructions
When generating your response, follow these formatting guidelines:
<format-instructions>
- Ensure the response is clear, succinct, and easy to understand.
- Use natural language and a conversational tone.
- Use a friendly and professional tone in your response.
- You can use markdown formatting for headings, lists, and emphasis, only if it is needed.
</format-instructions>
""".strip()

INSTRUCTION = """
<current-datetime>{datetime}</current-datetime>

Here is the user input to respond:
<user-input>
{user_input}
</user-input>

Please generate a comprehensive response based on the user input and previous conversation.
""".strip()


class QuickResponder:
    def __init__(self, model: ChatBedrockConverse) -> None:
        self.model = model.with_structured_output(ChatResponse)
        self.system_prompt = SYSTEM_PROMPT
        self.instruction = INSTRUCTION

    def _build_messages(self, state: ResearchState) -> PromptValue:
        return ChatPromptTemplate(
            [
                ("system", self.system_prompt),
                ("placeholder", "{conversation}"),
                ("human", self.instruction),
            ]
        ).invoke(
            {
                "conversation": state["messages"],
                "datetime": datetime.now(timezone.utc).isoformat(),
                "user_input": state["user_input"],
            }
        )

    def __call__(self, state: ResearchState) -> ResearchState:
        result = cast(ChatResponse, self.model.invoke(
            self._build_messages(state)))
        return {
            **state,
            "messages": [AIMessage(content=result.content)],
        }
